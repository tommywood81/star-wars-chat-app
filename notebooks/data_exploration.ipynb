{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Star Wars Script Data Exploration\n",
        "\n",
        "This notebook explores the structure of Star Wars script data, starting with \"A New Hope\" to understand:\n",
        "1. Script formatting and structure\n",
        "2. Character dialogue extraction patterns\n",
        "3. Scene and context information\n",
        "4. Data cleaning requirements for RAG pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up paths\n",
        "project_root = Path('..')\n",
        "data_dir = project_root / 'data' / 'raw'\n",
        "script_file = data_dir / 'STAR WARS A NEW HOPE.txt'\n",
        "\n",
        "print(f\"Project root: {project_root.absolute()}\")\n",
        "print(f\"Data directory: {data_dir.absolute()}\")\n",
        "print(f\"Script file exists: {script_file.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Examine Raw Script Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the script file\n",
        "with open(script_file, 'r', encoding='utf-8') as f:\n",
        "    script_text = f.read()\n",
        "\n",
        "print(f\"Total characters: {len(script_text):,}\")\n",
        "print(f\"Total lines: {len(script_text.splitlines()):,}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FIRST 1000 CHARACTERS:\")\n",
        "print(\"=\"*50)\n",
        "print(script_text[:1000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into lines for analysis\n",
        "lines = script_text.splitlines()\n",
        "\n",
        "print(f\"Total lines: {len(lines)}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SAMPLE LINES (50-100):\")\n",
        "print(\"=\"*50)\n",
        "for i, line in enumerate(lines[50:100], 50):\n",
        "    print(f\"{i:3}: {line[:80]}{'...' if len(line) > 80 else ''}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Identify Character Dialogue Patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look for character name patterns\n",
        "# Character names are typically in ALL CAPS followed by dialogue\n",
        "\n",
        "# Pattern: Character name at start of line (ALL CAPS)\n",
        "character_pattern = re.compile(r'^([A-Z][A-Z\\s\\-\\']+)\\s+(.+)$')\n",
        "\n",
        "# Find potential character lines\n",
        "potential_dialogue = []\n",
        "for i, line in enumerate(lines):\n",
        "    line = line.strip()\n",
        "    if line and character_pattern.match(line):\n",
        "        match = character_pattern.match(line)\n",
        "        character = match.group(1).strip()\n",
        "        dialogue = match.group(2).strip()\n",
        "        \n",
        "        # Filter out obvious non-character lines\n",
        "        if (len(character) <= 30 and  # Reasonable character name length\n",
        "            not character.startswith('INT.') and\n",
        "            not character.startswith('EXT.') and\n",
        "            not character.endswith('.') and\n",
        "            len(dialogue) > 10):  # Reasonable dialogue length\n",
        "            \n",
        "            potential_dialogue.append({\n",
        "                'line_num': i,\n",
        "                'character': character,\n",
        "                'dialogue': dialogue\n",
        "            })\n",
        "\n",
        "print(f\"Found {len(potential_dialogue)} potential dialogue lines\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SAMPLE DIALOGUE EXTRACTIONS:\")\n",
        "print(\"=\"*50)\n",
        "for i, item in enumerate(potential_dialogue[:10]):\n",
        "    print(f\"{i+1:2}. {item['character']:15} | {item['dialogue'][:60]}{'...' if len(item['dialogue']) > 60 else ''}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze character frequency\n",
        "character_counts = {}\n",
        "for item in potential_dialogue:\n",
        "    char = item['character']\n",
        "    character_counts[char] = character_counts.get(char, 0) + 1\n",
        "\n",
        "# Sort by frequency\n",
        "sorted_characters = sorted(character_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"TOP 20 CHARACTERS BY DIALOGUE COUNT:\")\n",
        "print(\"=\"*40)\n",
        "for char, count in sorted_characters[:20]:\n",
        "    print(f\"{char:20} | {count:3} lines\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Advanced Dialogue Extraction Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_dialogue_lines(script_text):\n",
        "    \"\"\"Extract character dialogue from Star Wars script text\"\"\"\n",
        "    lines = script_text.splitlines()\n",
        "    dialogue_data = []\n",
        "    current_scene = \"Unknown\"\n",
        "    \n",
        "    for i, line in enumerate(lines):\n",
        "        line = line.strip()\n",
        "        \n",
        "        # Track scene changes\n",
        "        if line.startswith('INT.') or line.startswith('EXT.'):\n",
        "            current_scene = line[:50]  # Truncate long scene descriptions\n",
        "            continue\n",
        "            \n",
        "        # Skip empty lines\n",
        "        if not line:\n",
        "            continue\n",
        "            \n",
        "        # Look for character dialogue pattern\n",
        "        char_match = re.match(r'^([A-Z][A-Z\\s\\-\\']+?)\\s+(.+)$', line)\n",
        "        \n",
        "        if char_match:\n",
        "            character = char_match.group(1).strip()\n",
        "            dialogue = char_match.group(2).strip()\n",
        "            \n",
        "            # Filter criteria for valid character lines\n",
        "            if (len(character) <= 25 and  # Reasonable name length\n",
        "                len(dialogue) >= 5 and   # Minimum dialogue length\n",
        "                not character.endswith('.') and  # Not scene direction\n",
        "                not character.startswith('FADE') and  # Not script direction\n",
        "                not character.startswith('CUT')):   # Not script direction\n",
        "                \n",
        "                dialogue_data.append({\n",
        "                    'line_number': i + 1,\n",
        "                    'scene': current_scene,\n",
        "                    'character': character,\n",
        "                    'dialogue': dialogue,\n",
        "                    'movie': 'A New Hope'\n",
        "                })\n",
        "    \n",
        "    return dialogue_data\n",
        "\n",
        "# Extract dialogue\n",
        "dialogue_data = extract_dialogue_lines(script_text)\n",
        "print(f\"Extracted {len(dialogue_data)} dialogue lines\")\n",
        "\n",
        "# Convert to DataFrame for easier analysis\n",
        "df = pd.DataFrame(dialogue_data)\n",
        "print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Character Analysis and Name Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Character name normalization mapping\n",
        "character_mapping = {\n",
        "    'THREEPIO': 'C-3PO',\n",
        "    'C-3PO': 'C-3PO',\n",
        "    'SEE-THREEPIO': 'C-3PO',\n",
        "    'ARTOO': 'R2-D2',\n",
        "    'R2-D2': 'R2-D2',\n",
        "    'ARTOO-DETOO': 'R2-D2',\n",
        "    'LUKE': 'Luke Skywalker',\n",
        "    'LEIA': 'Princess Leia',\n",
        "    'PRINCESS LEIA': 'Princess Leia',\n",
        "    'HAN': 'Han Solo',\n",
        "    'HAN SOLO': 'Han Solo',\n",
        "    'BEN': 'Obi-Wan Kenobi',\n",
        "    'OBI-WAN': 'Obi-Wan Kenobi',\n",
        "    'VADER': 'Darth Vader',\n",
        "    'DARTH VADER': 'Darth Vader',\n",
        "    'CHEWBACCA': 'Chewbacca',\n",
        "    'CHEWIE': 'Chewbacca'\n",
        "}\n",
        "\n",
        "def normalize_character_name(name):\n",
        "    \"\"\"Normalize character names to consistent format\"\"\"\n",
        "    name = name.strip().upper()\n",
        "    return character_mapping.get(name, name.title())\n",
        "\n",
        "# Apply normalization\n",
        "df['character_normalized'] = df['character'].apply(normalize_character_name)\n",
        "\n",
        "# Analyze character distribution\n",
        "print(\"CHARACTER DISTRIBUTION (after normalization):\")\n",
        "print(\"=\"*45)\n",
        "character_stats = df['character_normalized'].value_counts()\n",
        "print(character_stats.head(15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Quality Analysis and Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_dialogue_for_rag(df):\n",
        "    \"\"\"Clean dialogue data for RAG pipeline\"\"\"\n",
        "    clean_df = df.copy()\n",
        "    \n",
        "    # Add word count and character length\n",
        "    clean_df['word_count'] = clean_df['dialogue'].str.split().str.len()\n",
        "    clean_df['char_length'] = clean_df['dialogue'].str.len()\n",
        "    \n",
        "    # Filter criteria for high-quality dialogue\n",
        "    quality_mask = (\n",
        "        (clean_df['word_count'] >= 3) &  # At least 3 words\n",
        "        (clean_df['word_count'] <= 40) &  # Not too long\n",
        "        (clean_df['char_length'] >= 10) &  # At least 10 characters\n",
        "        (~clean_df['dialogue'].str.contains(r'^\\(.*\\)$', regex=True))  # Not just parenthetical\n",
        "    )\n",
        "    \n",
        "    clean_df = clean_df[quality_mask].copy()\n",
        "    \n",
        "    # Clean dialogue text - remove parenthetical directions\n",
        "    clean_df['dialogue_clean'] = clean_df['dialogue'].apply(lambda x: \n",
        "        re.sub(r'\\([^)]*\\)', '', x)  # Remove parenthetical directions\n",
        "        .strip()\n",
        "        .replace('  ', ' ')  # Remove double spaces\n",
        "    )\n",
        "    \n",
        "    # Remove lines where cleaning left very little content\n",
        "    clean_df = clean_df[clean_df['dialogue_clean'].str.len() > 5]\n",
        "    \n",
        "    # Focus on characters with sufficient dialogue (5+ lines)\n",
        "    char_counts = clean_df['character_normalized'].value_counts()\n",
        "    main_chars = char_counts[char_counts >= 5].index.tolist()\n",
        "    clean_df = clean_df[clean_df['character_normalized'].isin(main_chars)]\n",
        "    \n",
        "    return clean_df\n",
        "\n",
        "# Create clean dataset\n",
        "clean_df = clean_dialogue_for_rag(df)\n",
        "\n",
        "print(f\"Original dataset: {len(df)} lines\")\n",
        "print(f\"Clean dataset: {len(clean_df)} lines\")\n",
        "print(f\"Reduction: {(1 - len(clean_df)/len(df))*100:.1f}%\")\n",
        "\n",
        "print(\"\\nCLEAN DATASET - TOP 10 CHARACTERS:\")\n",
        "print(\"=\"*40)\n",
        "print(clean_df['character_normalized'].value_counts().head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample dialogue from main characters\n",
        "main_characters = ['Luke Skywalker', 'Princess Leia', 'Han Solo', 'C-3PO', 'Darth Vader', 'Obi-Wan Kenobi']\n",
        "\n",
        "print(\"SAMPLE DIALOGUE FROM MAIN CHARACTERS:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for char in main_characters:\n",
        "    char_dialogue = clean_df[clean_df['character_normalized'] == char]\n",
        "    if len(char_dialogue) > 0:\n",
        "        print(f\"\\n{char.upper()} ({len(char_dialogue)} lines):\")\n",
        "        print(\"-\" * (len(char) + 20))\n",
        "        # Show 3 sample lines\n",
        "        for i, (_, row) in enumerate(char_dialogue.head(3).iterrows()):\n",
        "            dialogue_text = row['dialogue_clean']\n",
        "            print(f\"{i+1}. {dialogue_text[:80]}{'...' if len(dialogue_text) > 80 else ''}\")\n",
        "            \n",
        "print(f\"\\nTotal characters with 5+ lines: {len(clean_df['character_normalized'].unique())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save clean dataset\n",
        "output_dir = project_root / 'data' / 'processed'\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "output_file = output_dir / 'a_new_hope_dialogue.csv'\n",
        "clean_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Clean dataset saved to: {output_file}\")\n",
        "print(f\"Final dataset shape: {clean_df.shape}\")\n",
        "\n",
        "# Display final structure\n",
        "print(\"\\nFINAL DATASET COLUMNS:\")\n",
        "print(\"=\"*30)\n",
        "for col in clean_df.columns:\n",
        "    print(f\"- {col}\")\n",
        "    \n",
        "print(f\"\\nDataset ready for embedding and RAG pipeline!\")\n",
        "print(f\"Total dialogue lines: {len(clean_df)}\")\n",
        "print(f\"Unique characters: {len(clean_df['character_normalized'].unique())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "### Data Quality Assessment:\n",
        "- Successfully extracted character dialogue from A New Hope script\n",
        "- Identified main characters and normalized their names\n",
        "- Cleaned data by removing stage directions and filtering low-quality lines\n",
        "- Created a structured dataset ready for embedding\n",
        "\n",
        "### Key Findings:\n",
        "- Script format is consistent and parseable\n",
        "- Main characters have sufficient dialogue for RAG\n",
        "- Data quality is good after cleaning\n",
        "\n",
        "### Ready for Next Steps:\n",
        "1. âœ… **Data exploration complete**\n",
        "2. ðŸ”„ **Next**: Set up embedding model (sentence-transformers)\n",
        "3. ðŸ”„ **Next**: Create PostgreSQL + pgvector database schema\n",
        "4. ðŸ”„ **Next**: Build retrieval system prototype\n",
        "5. ðŸ”„ **Next**: Test character-specific responses\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
